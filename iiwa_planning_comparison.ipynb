{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from pydrake.common import FindResourceOrThrow, RandomGenerator\n",
    "from pydrake.geometry import Box, Role, Sphere, RoleAssign\n",
    "from pydrake.geometry import SceneGraph, IllustrationProperties\n",
    "from pydrake.geometry.optimization import IrisInConfigurationSpace, IrisOptions\n",
    "from pydrake.math import RigidTransform, RollPitchYaw, RotationMatrix\n",
    "from pydrake.multibody.optimization import CalcGridPointsOptions, Toppra\n",
    "from pydrake.multibody.parsing import LoadModelDirectives, Parser, ProcessModelDirectives\n",
    "from pydrake.multibody.plant import AddMultibodyPlantSceneGraph, CoulombFriction, MultibodyPlant \n",
    "from pydrake.multibody.tree import RevoluteJoint, SpatialInertia, UnitInertia\n",
    "from pydrake.systems.framework import DiagramBuilder\n",
    "from pydrake.systems.meshcat_visualizer import ConnectMeshcatVisualizer\n",
    "from pydrake.all import MultibodyPositionToGeometryPose\n",
    "from pydrake.systems.primitives import TrajectorySource, Multiplexer, ConstantVectorSource\n",
    "from pydrake.systems.analysis import Simulator\n",
    "\n",
    "from comparison.planning import PRM, BiRRT\n",
    "\n",
    "from pydrake.trajectories import PiecewisePolynomial\n",
    "\n",
    "from meshcat import Visualizer\n",
    "import meshcat.geometry as g\n",
    "\n",
    "#from linear_spp import *\n",
    "#from bspline_spp import *\n",
    "#from iris_helpers import *\n",
    "#from comparison_helpers import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import to_hex\n",
    "from IPython.display import HTML, SVG\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "from itertools import combinations, chain\n",
    "\n",
    "from pydrake.solvers.gurobi import GurobiSolver\n",
    "from pydrake.solvers.mosek import MosekSolver\n",
    "GurobiSolver.AcquireLicense()\n",
    "MosekSolver.AcquireLicense()\n",
    "import cdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup meshcat\n",
    "from meshcat.servers.zmqserver import start_zmq_server_as_subprocess\n",
    "proc, zmq_url, web_url = start_zmq_server_as_subprocess(server_args=[])\n",
    "\n",
    "# Sporadically need to run `pkill -f meshcat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_alpha(plant, inspector, model_instances, alpha, scene_graph):\n",
    "    for model in model_instances:\n",
    "        for body_id in plant.GetBodyIndices(model):\n",
    "            frame_id = plant.GetBodyFrameIdOrThrow(body_id)\n",
    "            geometry_ids = inspector.GetGeometries(frame_id, Role.kIllustration)\n",
    "            for g_id in geometry_ids:\n",
    "                prop = inspector.GetIllustrationProperties(g_id)\n",
    "                new_props = IllustrationProperties(prop)\n",
    "                phong = prop.GetProperty(\"phong\", \"diffuse\")\n",
    "                phong.set(phong.r(), phong.g(), phong.b(), alpha)\n",
    "                new_props.UpdateProperty(\"phong\", \"diffuse\", phong)\n",
    "                scene_graph.AssignRole(plant.get_source_id(), g_id, new_props, RoleAssign.kReplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = Visualizer(zmq_url=zmq_url)\n",
    "vis.delete()\n",
    "display(vis.jupyter_cell())\n",
    "\n",
    "builder = DiagramBuilder()\n",
    "plant, scene_graph = AddMultibodyPlantSceneGraph(builder, time_step=0.0)\n",
    "parser = Parser(plant)\n",
    "#parser.package_map().Add( \"wsg_50_description\", os.path.dirname(FindResourceOrThrow(\n",
    " #           \"drake/manipulation/models/wsg_50_description/package.xml\")))\n",
    "\n",
    "floor_dim = np.array([4, 4, 0.2])\n",
    "floor = plant.AddRigidBody(\"floor\", SpatialInertia(\n",
    "        mass=1.0, p_PScm_E=np.array([0., 0., 0.]), G_SP_E=UnitInertia(1.0, 1.0, 1.0)))\n",
    "plant.WeldFrames(plant.world_frame(), floor.body_frame(), RigidTransform(p=np.array([0, 0, -floor_dim[2]/2.])))\n",
    "plant.RegisterVisualGeometry(floor, RigidTransform(), Box(*floor_dim), \"floor_vis\",\n",
    "                             np.array([0.5, 0.5, 0.5, 1.]))\n",
    "plant.RegisterCollisionGeometry(floor, RigidTransform(), Box(*floor_dim), \"florr_collision\",\n",
    "                                CoulombFriction(0.9, 0.8))\n",
    "\n",
    "directives_file = \"./models/iiwa14_spheres_collision_welded_gripper.yaml\"\n",
    "directives = LoadModelDirectives(directives_file)\n",
    "models = ProcessModelDirectives(directives, plant, parser)\n",
    "[iiwa, wsg, shelf, binR, binL] =  models\n",
    "\n",
    "visual_iiwas = []\n",
    "visual_wsgs = []\n",
    "#iiwa_file = FindResourceOrThrow(\"./models/iiwa_description/urdf/iiwa14_spheres_collision.urdf\")\n",
    "#wsg_file = FindResourceOrThrow(\"drake/planning/models/schunk_wsg_50_welded_fingers.sdf\")\n",
    "    \n",
    "\n",
    "plant.Finalize()\n",
    "\n",
    "viz_role = Role.kIllustration\n",
    "# viz_role = Role.kProximity\n",
    "visualizer = ConnectMeshcatVisualizer(builder, scene_graph, zmq_url=zmq_url,\n",
    "                                      delete_prefix_on_load=False, role=viz_role)\n",
    "diagram = builder.Build()\n",
    "\n",
    "\n",
    "\n",
    "visualizer.load()\n",
    "context = diagram.CreateDefaultContext()\n",
    "plant_context = plant.GetMyContextFromRoot(context)\n",
    "plant_context = plant.GetMyMutableContextFromRoot(context)\n",
    "q0 =      [-0.43303849430001307,\n",
    "    0.15450520762404665,\n",
    "    0.30334346818001523,\n",
    "    -1.0376976962796667,\n",
    "    0.11739903437607266,\n",
    "    0.5348776947156673,\n",
    "    1.0783084430904017]\n",
    "plant.SetPositions(plant_context,q0)\n",
    "diagram.Publish(context)\n",
    "\n",
    "PositionUpperLimits = plant.GetPositionUpperLimits()\n",
    "PositionLowerLimits = plant.GetPositionLowerLimits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trajectory(traj_list, show_line = False, iiwa_ghosts = [], alpha = 0.5, regions = []):\n",
    "    \"\"\" This will only execute the first trajectory\"\"\"\n",
    "    if not isinstance(traj_list, list):\n",
    "        traj_list = [traj_list]\n",
    "    \n",
    "    combined_traj = combine_trajectory(traj_list)\n",
    "    vis = Visualizer(zmq_url=zmq_url)\n",
    "    vis.delete()\n",
    "\n",
    "    builder = DiagramBuilder()\n",
    "    scene_graph = builder.AddSystem(SceneGraph())\n",
    "    plant = MultibodyPlant(time_step=0.0)\n",
    "    plant.RegisterAsSourceForSceneGraph(scene_graph)\n",
    "    inspector = scene_graph.model_inspector()\n",
    "    \n",
    "    \n",
    "    parser = Parser(plant, scene_graph)\n",
    "    parser.package_map().Add( \"wsg_50_description\", os.path.dirname(FindResourceOrThrow(\n",
    "            \"drake/manipulation/models/wsg_50_description/package.xml\")))\n",
    "\n",
    "    floor_dim = np.array([4, 4, 0.2])\n",
    "    floor = plant.AddRigidBody(\"floor\", SpatialInertia(\n",
    "        mass=1.0, p_PScm_E=np.array([0., 0., 0.]), G_SP_E=UnitInertia(1.0, 1.0, 1.0)))\n",
    "    plant.WeldFrames(plant.world_frame(), floor.body_frame(), RigidTransform(p=np.array([0, 0, -floor_dim[2]/2.])))\n",
    "    plant.RegisterVisualGeometry(floor, RigidTransform(), Box(*floor_dim), \"floor_vis\",\n",
    "                             np.array([0.5, 0.5, 0.5, 0.0]))\n",
    "    plant.RegisterCollisionGeometry(floor, RigidTransform(), Box(*floor_dim), \"florr_collision\",\n",
    "                                CoulombFriction(0.9, 0.8))\n",
    "\n",
    "    directives_file = FindResourceOrThrow(\"drake/planning/models/iiwa14_spheres_collision_welded_gripper.yaml\")\n",
    "    directives = LoadModelDirectives(directives_file)\n",
    "    models = ProcessModelDirectives(directives, plant, parser)\n",
    "    [iiwa, wsg, shelf, binR, binL] =  models\n",
    "    \n",
    "    #add clones versions of the iiwa\n",
    "    if len(iiwa_ghosts):\n",
    "        lower_alpha(plant, inspector, [iiwa.model_instance, wsg.model_instance], alpha,scene_graph)\n",
    "    visual_iiwas = []\n",
    "    visual_wsgs = []\n",
    "    iiwa_file = FindResourceOrThrow(\"drake/manipulation/models/iiwa_description/urdf/iiwa14_spheres_collision.urdf\")\n",
    "    wsg_file = FindResourceOrThrow(\"drake/planning/models/schunk_wsg_50_welded_fingers.sdf\")\n",
    "    \n",
    "    for i, q in enumerate(iiwa_ghosts):\n",
    "        new_iiwa = parser.AddModelFromFile(iiwa_file, \"vis_iiwa_\"+str(i))\n",
    "        new_wsg = parser.AddModelFromFile(wsg_file, \"vis_wsg_\"+str(i))\n",
    "        plant.WeldFrames(plant.world_frame(), plant.GetFrameByName(\"base\", new_iiwa), RigidTransform())\n",
    "        plant.WeldFrames(plant.GetFrameByName(\"iiwa_link_7\", new_iiwa), plant.GetFrameByName(\"body\", new_wsg),\n",
    "                         RigidTransform(rpy=RollPitchYaw([np.pi/2., 0, 0]), p=[0, 0, 0.114]))\n",
    "        visual_iiwas.append(new_iiwa)\n",
    "        visual_wsgs.append(new_wsg)\n",
    "        lower_alpha(plant, inspector, [new_iiwa, new_wsg], alpha, scene_graph)\n",
    "        index = 0\n",
    "        for joint_index in plant.GetJointIndices(visual_iiwas[i]):\n",
    "            joint = plant.get_mutable_joint(joint_index)\n",
    "            if isinstance(joint, RevoluteJoint):\n",
    "                joint.set_default_angle(q[index])\n",
    "                index += 1\n",
    "    \n",
    "    plant.Finalize()\n",
    "\n",
    "    to_pose = builder.AddSystem(MultibodyPositionToGeometryPose(plant))\n",
    "    builder.Connect(to_pose.get_output_port(), scene_graph.get_source_pose_port(plant.get_source_id()))\n",
    "\n",
    "    traj_system = builder.AddSystem(TrajectorySource(combined_traj))\n",
    "\n",
    "    mux = builder.AddSystem(Multiplexer([7 for _ in range(1 + len(iiwa_ghosts))]))\n",
    "    builder.Connect(traj_system.get_output_port(), mux.get_input_port(0))\n",
    "    \n",
    "    for i, q in enumerate(iiwa_ghosts):\n",
    "        ghost_pos = builder.AddSystem(ConstantVectorSource(q))\n",
    "        builder.Connect(ghost_pos.get_output_port(), mux.get_input_port(1+i) )\n",
    "    \n",
    "    \n",
    "    builder.Connect(mux.get_output_port(), to_pose.get_input_port())\n",
    "\n",
    "\n",
    "    viz_role = Role.kIllustration\n",
    "    # viz_role = Role.kProximity\n",
    "    visualizer = ConnectMeshcatVisualizer(builder, scene_graph, zmq_url=zmq_url,\n",
    "                                      delete_prefix_on_load=False, role=viz_role)\n",
    "\n",
    "    diagram = builder.Build()\n",
    "    \n",
    "    if show_line:\n",
    "        X_lists = []\n",
    "        for traj in traj_list:\n",
    "            #X_list =  [ForwardKinematics(k) for k in traj.vector_values(traj.get_segment_times()).T.tolist()]\n",
    "            X_list = ForwardKinematics(traj.vector_values(np.linspace(traj.start_time(), traj.end_time(), 15000)).T.tolist())\n",
    "            X_lists.append(X_list)\n",
    "            \n",
    "        c_list_hex = [0xFF0000,0x00FF00, 0x0000FF]\n",
    "        c_list_rgb = [[i/255 for i in (0, 0, 255, 255)],[i/255 for i in (255, 191, 0, 255)],[i/255 for i in (255, 64, 0, 255)]]\n",
    "\n",
    "        line_type = [('line',g.MeshBasicMaterial), ('phong',g.MeshPhongMaterial), ('lambert',g.MeshLambertMaterial)]\n",
    "        \n",
    "        for i, X_list in enumerate(X_lists):\n",
    "            vertices = list(map(lambda X: X.translation(), X_list))\n",
    "            colors = [np.array(c_list_rgb[i]) for _ in range(len(X_list))]\n",
    "            vertices = np.stack(vertices).astype(np.float32).T\n",
    "            colors = np.array(colors).astype(np.float32).T\n",
    "            vis[\"paths\"][str(i)].set_object(g.Points(g.PointsGeometry(vertices, color=colors),\n",
    "                                            g.PointsMaterial(size=0.015)))\n",
    "        \n",
    "        \n",
    "        reg_colors = plt.cm.viridis(np.linspace(0, 1,len(regions)))\n",
    "        reg_colors[:,3] = 1.0\n",
    "        \n",
    "        for i, reg in enumerate(regions):\n",
    "            X_reg = ForwardKinematics(spider_web(reg))\n",
    "            vertices = list(map(lambda X: X.translation(), X_reg))\n",
    "            colors = [reg_colors[i] for _ in range(len(X_reg))]\n",
    "            vertices = np.stack(vertices).astype(np.float32).T\n",
    "            colors = np.array(colors).astype(np.float32).T\n",
    "            vis[\"regions\"][str(i)].set_object(g.Points(g.PointsGeometry(vertices, color=colors),\n",
    "                                                       g.PointsMaterial(size=0.015)))\n",
    "        \n",
    "    visualizer.load()\n",
    "    simulator = Simulator(diagram)\n",
    "    visualizer.start_recording()\n",
    "    simulator.AdvanceTo(combined_traj.end_time())\n",
    "    visualizer.publish_recording()\n",
    "    return vis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Iris Regions\n",
    "### via manual seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_options = IrisOptions()\n",
    "iris_options.require_sample_point_is_contained = True\n",
    "iris_options.iteration_limit = 10\n",
    "iris_options.termination_threshold = -1\n",
    "iris_options.relative_termination_threshold = 0.01\n",
    "iris_options.enable_ibex = False\n",
    "CORE_CNT = mp.cpu_count() # you may edit this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used for paper \n",
    "seed_points =  {\"Above Shelve\": [0, 0.4, 0, -0.8, 0, 0.35, 1.57],   \n",
    "                \"Top Rack\":[0, 0.45, 0, -1.35, 0, -0.25, 1.57],   \n",
    "                \"Middle Rack\":[0, 0.8, 0, -1.5, 0, -0.7, 1.57],       \n",
    "                \"Right Bin\":[1.57, 0.7, 0, -1.6, 0, 0.8, 1.57], \n",
    "                \"Left Bin\":[-1.57, 0.7, 0, -1.6, 0, 0.8, 1.57],\n",
    "                \"Front to Shelve\":[0, 0.2, 0, -2.09, 0, -0.3, 1.57], \n",
    "                \"Right to Shelve\":[0.8, 0.7, 0, -1.6, 0, 0, 1.57],\n",
    "                \"Left to Shelve\":[-0.8, 0.7, 0, -1.6, 0, 0, 1.57]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimized for paper\n",
    "seed_points = { \"Above Shelve\": [0, 0.4, 0, -0.8, 0, 0.35, 1.57],       \n",
    "                \"Top Rack\": [0, 0.45, 0, -1.35, 0, -0.25, 1.57],    \n",
    "                \"Middle Rack\": [0, 0.8, 0, -1.5, 0, -0.7, 1.57],       \n",
    "                \"Right Bin\": [1.57, 0.7, 0, -1.6, 0, 0.8, 0],          \n",
    "                \"Left Bin\": [-1.57, 0.7, 0, -1.6, 0, 0.8, 0],\n",
    "                \"Helper 1\": [0.0, 0.175, 0.0, -1.675, 0.0, -0.275, 1.57],\n",
    "                \"Helper 2\":[-0.23670698873773643, 0.0869880191351135,\n",
    "                                -0.14848147591054467, -1.8845683628360246,\n",
    "                                    0.11582904486351761, -0.004801857412368382, 1.2343852721657547],\n",
    "                \"Helper 3\":[0.1901439226352184, 0.24791935747561322, 0.026105794277764514,\n",
    "                                -1.862822617783086, 0.2509538957570004, -0.2466088852764272, 1.3435623440091402],\n",
    "                \"Helper 4\":[-0.43303849430001307, 0.15450520762404665, 0.30334346818001523,\n",
    "                                -1.0376976962796667, 0.11739903437607266, 0.5348776947156673, 1.0783084430904017]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calcRegion(seed, verbose):\n",
    "    start_time = time.time()\n",
    "    context = diagram.CreateDefaultContext()\n",
    "    plant_context = plant.GetMyContextFromRoot(context)\n",
    "    plant.SetPositions(plant_context, seed)\n",
    "    hpoly = IrisInConfigurationSpace(plant, plant_context, iris_options)\n",
    "    print(\"Seed:\", seed, \"\\tTime:\", time.time() - start_time, flush=True)\n",
    "    return hpoly\n",
    "\n",
    "def generateRegions(seed_points, verbose = True):\n",
    "    seeds = list(seed_points.values()) if type(seed_points) is dict else seed_points\n",
    "    regions = []\n",
    "    loop_time = time.time()\n",
    "    with mp.Pool(processes = CORE_CNT) as pool:\n",
    "        regions = pool.starmap(calcRegion, [[seed, verbose] for seed in seeds])\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Loop time:\", time.time() - loop_time)\n",
    "    \n",
    "    if type(seed_points) is dict:\n",
    "        return dict(list(zip(seed_points.keys(), regions)))\n",
    "    \n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = generateRegions(seed_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./IRIS.reg', 'wb') as f:\n",
    "    pickle.dump(regions,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate PRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = np.pi/32\n",
    "collision_step_size = step_size/128\n",
    "#collision_step_size = step_size/8\n",
    "solve_timeout = 100\n",
    "K = 5\n",
    "roadmap_size = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prm = PRM(K, solve_timeout, plant, plant_context, step_size, collision_step_size)\n",
    "#stats = prm.Grow(roadmap_size)\n",
    "#roadmap = prm.roadmap\n",
    "print(stats) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the final Demonstration \n",
    "Unfortunately this is out of order. PRM is not capable of reaching into the shelf directly\n",
    "So we have to use BiRRT to connect some subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in keypoints:\n",
    "    AddNodeToRoadmap(q, NNDistanceDirection(), roadmap, distance_fn,check_edge_validity_fn, K, False,True,False )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in RRT_Connect([0, 0.4, 0, -0.8, 0, 0.35, 1.57],[0, 0.45, 0, -1.35, 0, -0.25, 1.57]).Path():\n",
    "    AddNodeToRoadmap(q, NNDistanceDirection(), roadmap, distance_fn,check_edge_validity_fn, K, False,True,False )\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in RRT_Connect([0, 0.45, 0, -1.35, 0, -0.25, 1.57], [0, 0.8, 0, -1.5, 0, -0.7, 1.57]).Path():\n",
    "    AddNodeToRoadmap(q, NNDistanceDirection(), roadmap, distance_fn,check_edge_validity_fn, K, False,True,False )\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_prm_path(demo2, 5, verbose = True, smoothing = False, roadmap=roadmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save roadmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./PRM.rmp', 'wb') as f:\n",
    "    pickle.dump(roadmap,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Iris Regions and Roadmap\n",
    "\n",
    "### make sure to run SimpleLinearSPP before running the comparison below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./PRM_BiRRT_Demo_1.rmp', 'rb') as f:\n",
    "    roadmap = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./PRM_BiRRT_super_dense.rmp', 'rb') as f:\n",
    "    roadmap = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./IRIS_paper_intuitive.reg', 'rb') as f:\n",
    "    regions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./IRIS_paper_optimal.reg', 'rb') as f:\n",
    "    regions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spp = SimplerLinearSPP(regions.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(spp.VisualizeGraph()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bspp = BsplineSPP(regions.copy(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(bspp.VisualizeGraph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PRM & Run Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_sampling_fn():\n",
    "    nq = len(PositionLowerLimits)\n",
    "    sample = np.random.rand(nq) * (PositionUpperLimits - PositionLowerLimits) + PositionLowerLimits\n",
    "    \n",
    "    #check if sampe is in a region\n",
    "    sampe_in_regions = False\n",
    "    for R in regions:\n",
    "        if R.PointInSet(sample):\n",
    "            sampe_in_regions = True\n",
    "            break\n",
    "\n",
    "    if not sampe_in_regions:\n",
    "        return None\n",
    "    \n",
    "    #verify sample has a collision free configuration \n",
    "    plant.SetPositions(plant_context, sample)\n",
    "    query_object = plant.get_geometry_query_input_port().Eval(plant_context)\n",
    "    if query_object.HasCollisions():\n",
    "        return None\n",
    "    \n",
    "    return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prm_path(sequence, seed, verbose = False, smoothing = False, roadmap = roadmap):\n",
    "    path = [sequence[0]]\n",
    "    start_time = time.time()\n",
    "    for start_pt, goal_pt in zip(sequence[:-1], sequence[1:]):\n",
    "        prm_path = QueryPath([start_pt], [goal_pt], roadmap, distance_fn,\n",
    "                check_edge_validity_fn, K,\n",
    "                use_parallel=False,\n",
    "                distance_is_symmetric=True,\n",
    "                add_duplicate_states=False,\n",
    "                limit_astar_pqueue_duplicates=True).Path()\n",
    "        if smoothing:\n",
    "            prm_path = ShortcutSmoothPath(prm_path, 100, 100, 1, 0.5, 0.5, False,\n",
    "                               check_edge_validity_fn,distance_fn,\n",
    "                               InterpolateWaypoint, RandomGenerator(seed))\n",
    "        if len(prm_path) == 0:\n",
    "            if verbose:\n",
    "                print(f\"Failed between {start_pt} and {goal_pt}\")\n",
    "            return None\n",
    "        \n",
    "        path += prm_path[1:]\n",
    "            \n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Time: {round(time.time() - start_time, 3)}s\")\n",
    "        \n",
    "    return np.stack(path).T\n",
    "\n",
    "def get_simple_spp_path(sequence, verbose = False):\n",
    "    path = [sequence[0]]\n",
    "    start_time = time.time()\n",
    "    for start_pt, goal_pt in zip(sequence[:-1], sequence[1:]):\n",
    "        waypoints, _, _ = spp.SolvePath(start_pt, goal_pt, True, verbose)\n",
    "        if waypoints is None:\n",
    "            if verbose:\n",
    "                print(f\"Failed between {start_pt} and {goal_pt}\")\n",
    "            return None\n",
    "        path += waypoints.T[1:].tolist()\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Time: {round(time.time() - start_time, 3)}s\")\n",
    "    return np.stack(path).T\n",
    "\n",
    "\n",
    "#for comparison function\n",
    "\n",
    "def simple_linear_rebuild(start_pt, goal_pt):\n",
    "    path = get_simple_spp_path([start_pt, goal_pt])\n",
    "    if path is None:\n",
    "        return None, None\n",
    "    return make_traj(path), None\n",
    "\n",
    "def bspline_rebuild(start_pt, goal_pt):\n",
    "    path, _, _ = bspp.SolvePath(start_pt, goal_pt, True, True)\n",
    "    if path is None:\n",
    "        return None, None\n",
    "    return path, None\n",
    "\n",
    "def dense_prm(start_pt, goal_pt):\n",
    "    path = get_prm_path([start_pt, goal_pt], 5)\n",
    "    if path is None:\n",
    "        return None, None\n",
    "    return make_traj(path), None\n",
    "\n",
    "def smoothed_dense_prm(start_pt, goal_pt):\n",
    "    path = get_prm_path([start_pt, goal_pt], 5, False, True)\n",
    "    if path is None:\n",
    "        return None, None\n",
    "    return make_traj(path), None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_a = [[0, 0.4, 0, -0.8, 0, 0.35, 1.57],        # above shelf\n",
    "            [0, 0.45, 0, -1.35, 0, -0.25, 1.57]]     # in shelf 1\n",
    "\n",
    "demo_b = [[0, 0.45, 0, -1.35, 0, -0.25, 1.57],     # in shelf 1\n",
    "            [0, 0.8, 0, -1.5, 0, -0.7, 1.57]]        # in shelf 2 \n",
    "\n",
    "demo_c = [[0, 0.8, 0, -1.5, 0, -0.7, 1.57],        # in shelf 2 \n",
    "            [1.57, 0.7, 0, -1.6, 0, 0.8, 1.57]]      # in left  bin\n",
    "\n",
    "demo_d = [[1.57, 0.7, 0, -1.6, 0, 0.8, 1.57],      # in left  bin\n",
    "            [-1.57, 0.7, 0, -1.6, 0, 0.8, 1.57]]      # in right  bin\n",
    "\n",
    "demo_e = [[-1.57, 0.7, 0, -1.6, 0, 0.8, 1.57],      # in right  bin\n",
    "            [0, 0.4, 0, -0.8, 0, 0.35, 1.57]]      # above shelf\n",
    "\n",
    "demo_circle = [[0, 0.4, 0, -0.8, 0, 0.35, 1.57],        # above shelf\n",
    "                [0, 0.45, 0, -1.35, 0, -0.25, 1.57],     # in shelf 1\n",
    "               [0, 0.8, 0, -1.5, 0, -0.7, 1.57],        # in shelf 2 \n",
    "                 [1.57, 0.7, 0, -1.6, 0, 0.8, 1.57],      # in left  bin\n",
    "                [-1.57, 0.7, 0, -1.6, 0, 0.8, 1.57],      # in right  bin\n",
    "                 [0, 0.4, 0, -0.8, 0, 0.35, 1.57]]      # above shelf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_trajectory(traj_list, wait = 2):\n",
    "    knotList = []\n",
    "    time_delta = 0\n",
    "    time_list = []\n",
    "    for traj in traj_list:\n",
    "        knots = traj.vector_values(traj.get_segment_times()).T\n",
    "        knotList.append(knots)\n",
    "        \n",
    "        duration = traj.end_time() - traj.start_time()\n",
    "        offset = 0 \n",
    "        try:\n",
    "            offset = time_list[-1][-1] + 0.1\n",
    "        except:\n",
    "            pass\n",
    "        time_list.append(np.linspace(offset, duration + offset,  knots.shape[0]))\n",
    "        \n",
    "        #add wait time\n",
    "        if wait > 0.0:\n",
    "            knotList.append(knotList[-1][-1,:])\n",
    "            time_list.append(np.array([time_list[-1][-1] + wait]))\n",
    "            \n",
    "        \n",
    "    path = np.vstack(knotList).T\n",
    "    time_break = np.hstack(time_list)\n",
    "\n",
    "    return PiecewisePolynomial.FirstOrderHold(time_break, path)\n",
    "        \n",
    "def make_traj(path, speed = 2):\n",
    "    t_breaks = [0]\n",
    "    movement_between_segment = np.sqrt(np.sum(np.square(path.T[1:,:] - path.T[:-1,:]), axis = 1))\n",
    "    for s in movement_between_segment/speed:\n",
    "        t_breaks += [s + t_breaks[-1]]\n",
    "    return PiecewisePolynomial.FirstOrderHold(t_breaks, path)\n",
    "\n",
    "\n",
    "def get_traj_length(trajectory, bspline = False):\n",
    "    path_length = 0\n",
    "    if bspline:\n",
    "        knots = trajectory.vector_values(np.linspace(trajectory.start_time(), trajectory.end_time(), 1000))\n",
    "    else:\n",
    "        knots = trajectory.vector_values(trajectory.get_segment_times())\n",
    "    \n",
    "    individual_mov = []\n",
    "    for ii in range(knots.shape[1] - 1):\n",
    "        path_length += np.linalg.norm(knots[:, ii+1] - knots[:, ii])\n",
    "        individual_mov.append([np.linalg.norm(knots[j, ii+1] - knots[j, ii]) for j in range(7)])\n",
    "    \n",
    "    print(np.sum(individual_mov, axis = 0))\n",
    "    return path_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "execute_demo = demo_a\n",
    "linear_spp_traj = make_traj(get_simple_spp_path(execute_demo, verbose = True), speed = 2)\n",
    "print(f\"Linear SPP length: {get_traj_length(linear_spp_traj)}\")\n",
    "\n",
    "# prm_traj = make_traj(get_prm_path(execute_demo, 5, verbose = True, smoothing = False, roadmap=roadmap), speed = 2)\n",
    "# print(f\"PRM length: {get_traj_length(prm_traj)}\")\n",
    "\n",
    "smoothed_prm_traj = make_traj(get_prm_path(execute_demo, 5, verbose = True, smoothing = True, roadmap=roadmap), speed = 2)\n",
    "print(f\"smoothed PRM length: {get_traj_length(smoothed_prm_traj)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_meshcat = visualize_trajectory([linear_spp_traj,prm_traj,smoothed_prm_traj],\n",
    "                     show_line = True,\n",
    "                     iiwa_ghosts = execute_demo,\n",
    "                     alpha =  0.3,\n",
    "                     regions = [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_meshcat = visualize_trajectory([linear_spp_traj,prm_traj,smoothed_prm_traj],\n",
    "                     show_line = False,\n",
    "                     iiwa_ghosts = [[0, 0.2, 0, -2.09, 0, -0.3, 1.57],[0.8, 0.7, 0, -1.6, 0, 0, 1.57],[-0.8, 0.7, 0, -1.6, 0, 0, 1.57]],\n",
    "                     alpha =  0.3,\n",
    "                     regions = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_meshcat.static_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"SPP_PRM_comparison_simple.html\", \"w\") as f:\n",
    "    f.write(vis_meshcat.static_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_trajectory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools to Analyze roadmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_subgraphs_idx(roadmap):\n",
    "    milestones_idx = set(range(len(roadmap.GetNodesMutable())))\n",
    "    subgraphs = []\n",
    "    \n",
    "    idx = 0\n",
    "    while len(milestones_idx) != 0:\n",
    "        #pick a random milestone\n",
    "        subgraph = set()\n",
    "        root = milestones_idx.pop()\n",
    "        queue = [root]\n",
    "    \n",
    "        #start expanding bfs style \n",
    "        while len(queue) != 0:\n",
    "            expand_node_idx = queue.pop(0)\n",
    "        \n",
    "            if expand_node_idx in subgraph:\n",
    "                #already expanded\n",
    "                continue\n",
    "            \n",
    "            subgraph.add(expand_node_idx)\n",
    "            expand_node = roadmap.GetNodeImmutable(expand_node_idx)\n",
    "\n",
    "            if list(expand_node.GetValueImmutable()) in seed_points:\n",
    "                print(idx, expand_node.GetValueImmutable())\n",
    "            for child in [edge.GetToIndex() for edge in expand_node.GetOutEdgesImmutable()]:\n",
    "                queue.append(child)\n",
    "    \n",
    "        subgraphs.append(subgraph)\n",
    "        idx +=1\n",
    "        #remove subgraph from milestones \n",
    "        milestones_idx -= set(subgraph)\n",
    "    return milestones_idx, subgraphs\n",
    "\n",
    "milestones_idx, subgraphs = return_subgraphs_idx(roadmap)\n",
    "\n",
    "print(f\"Found {len(subgraphs)} subgraphs, with sizes {list(map(len,subgraphs))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RRT Connect function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_fn(nearest, sample, is_start_tree):\n",
    "    total_dist = distance_fn(nearest, sample)\n",
    "    total_steps = int(np.ceil(total_dist / step_size))        \n",
    "        \n",
    "    propagated_states = []\n",
    "    parent_offset = -1\n",
    "    current = nearest\n",
    "    for steps in range(total_steps):\n",
    "        current_target = None\n",
    "        target_dist = distance_fn(current, sample)\n",
    "        if target_dist > step_size:\n",
    "            #interpolate\n",
    "            current_target = current + step_size/target_dist * (sample - current)\n",
    "            \n",
    "        elif target_dist < 1e-6:\n",
    "            break\n",
    "        else:\n",
    "            current_target = sample\n",
    "        \n",
    "        if not check_edge_validity_fn(current, current_target):\n",
    "            return propagated_states\n",
    "    \n",
    "                    \n",
    "        propagated_states.append(PropagatedState(state=current_target, relative_parent_index=parent_offset))\n",
    "        parent_offset += 1\n",
    "        current = current_target\n",
    "\n",
    "    return propagated_states\n",
    "\n",
    "def states_connected_fn(source, target, is_start_tree):\n",
    "    return np.linalg.norm(source - target) < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RRT_Connect(q_ini,q_final):\n",
    "    solve_timeout_rrt = 500\n",
    "    start_tree = [SimpleRRTPlannerState(q_ini)]\n",
    "    end_tree = [SimpleRRTPlannerState(q_final)]\n",
    "    \n",
    "    goal_bias = 0.05\n",
    "    \n",
    "    def birrt_sampling():\n",
    "        if np.random.rand() < goal_bias:\n",
    "            if np.random.rand() < 0.5:\n",
    "                return q_ini\n",
    "            else:\n",
    "                if np.random.rand() < 0.5:\n",
    "                    return [ 0.18731861,  0.37941396, -0.27091993, -0.84213184, -0.21627076,\n",
    "           0.45351121,  1.55646851]\n",
    "                else:\n",
    "                    return q_final\n",
    "        return np.random.rand(len(PositionLowerLimits))*(PositionUpperLimits-PositionLowerLimits) + PositionLowerLimits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nearest_neighbor_fn = MakeKinematicLinearBiRRTNearestNeighborsFunction(distance_fn=distance_fn, use_parallel = False)\n",
    "\n",
    "    termination_fn = MakeBiRRTTimeoutTerminationFunction(solve_timeout_rrt)\n",
    "    \n",
    "    connect_result = BiRRTPlanSinglePath(\n",
    "            start_tree=start_tree, goal_tree=end_tree,\n",
    "            state_sampling_fn=birrt_sampling,\n",
    "            nearest_neighbor_fn=nearest_neighbor_fn, propagation_fn=connect_fn,\n",
    "            state_added_callback_fn=None,\n",
    "            states_connected_fn=states_connected_fn,\n",
    "            goal_bridge_callback_fn=None,\n",
    "            tree_sampling_bias=0.5, p_switch_tree=0.25,\n",
    "            termination_check_fn=termination_fn, rng=RandomGenerator(5))\n",
    "    return connect_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rrt_path(sequence, seed, verbose = False, smoothing = False):\n",
    "    path = [sequence[0]]\n",
    "    start_time = time.time()\n",
    "    for start_pt, goal_pt in zip(sequence[:-1], sequence[1:]):\n",
    "        prm_path =RRT_Connect(start_pt, goal_pt).Path()\n",
    "        if smoothing:\n",
    "            prm_path = ShortcutSmoothPath(prm_path, 400, 400, 2, 0.5, 0.5, False,\n",
    "                               check_edge_validity_fn,distance_fn,\n",
    "                               InterpolateWaypoint, RandomGenerator(seed))\n",
    "        if len(prm_path) == 0:\n",
    "            if verbose:\n",
    "                print(f\"Failed between {start_pt} and {goal_pt}\")\n",
    "            return None\n",
    "        \n",
    "        for pt in prm_path[1:]:\n",
    "            path.append(pt)\n",
    "            \n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Time: {round(time.time() - start_time, 3)}s\")\n",
    "        \n",
    "    return np.stack(path).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
